{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NoSQL Database (MongoDB):\n",
        "\n",
        "NoSQL databases can be valuable when dealing with **unstructured data**\n",
        "\n",
        "**NoSQL Databases** (e.g., MongoDB, Cassandra):\n",
        "\n",
        "Relevance: NoSQL databases are commonly used in AI and machine learning projects, especially when dealing with large and unstructured data. They are well-suited for handling data types like text, images, and sensor data.\n",
        "\n",
        "Importance: Proficiency in NoSQL databases can be valuable for data preprocessing, storage, and retrieval in AI applications."
      ],
      "metadata": {
        "id": "U0i_YRDpnL5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In AI applications, especially those involving large-scale data and complex data structures, NoSQL databases can play a crucial role in handling various data-related tasks. Some important data-related tasks in AI with NoSQL databases include:\n",
        "\n",
        "- Data Ingestion: NoSQL databases can efficiently ingest and store large volumes of structured, semi-structured, and unstructured data. This is essential for AI projects that require data from diverse sources, such as text, images, videos, sensor data, and more.\n",
        "\n",
        "- Data Storage: NoSQL databases offer flexible data models, making it easier to store and manage different types of data. For example, document-based NoSQL databases like MongoDB can store JSON or BSON documents, while graph databases like Neo4j can model and store complex relationships between data entities.\n",
        "\n",
        "- Data Preprocessing: AI models often require data preprocessing to clean, transform, and enrich the data. NoSQL databases can support data preprocessing by providing tools and APIs to manipulate and transform data within the database itself.\n",
        "\n",
        "- Data Retrieval: Efficient data retrieval is critical for training AI models and making real-time predictions. NoSQL databases can provide high-speed data retrieval through indexing, caching, and sharding mechanisms.\n",
        "\n",
        "- Scalability: NoSQL databases are designed to scale horizontally, which means they can handle growing datasets and increasing workloads. This scalability is crucial for AI applications that need to process vast amounts of data.\n",
        "\n",
        "- Real-time Analytics: Many NoSQL databases offer built-in support for real-time analytics, allowing AI applications to analyze streaming data and make rapid decisions based on the latest information.\n",
        "\n",
        "- Graph Processing: For AI projects involving graph-based data, such as social networks, knowledge graphs, or recommendation systems, graph databases excel at traversing complex relationships and uncovering valuable insights.\n",
        "\n",
        "- Machine Learning Integration: NoSQL databases can integrate with machine learning frameworks and libraries, enabling AI developers to build and deploy models using data stored in the database. This tight integration simplifies the training and inference process.\n",
        "\n",
        "- Data Versioning: NoSQL databases can support data versioning, which is valuable for AI experiments and model training. Developers can track changes to datasets over time and revert to previous versions if needed.\n",
        "\n",
        "- Security and Access Control: NoSQL databases offer security features to protect sensitive AI data. Role-based access control and encryption mechanisms help ensure that only authorized users can access and modify data.\n",
        "\n",
        "- Backup and Recovery: NoSQL databases provide tools for data backup and recovery, which is essential for safeguarding valuable AI datasets and ensuring data availability in case of failures.\n",
        "\n",
        "- Data Exploration: NoSQL databases often include tools for data exploration and visualization, helping data scientists and AI researchers gain insights from their data.\n",
        "\n",
        "- Performance Optimization: NoSQL databases can be fine-tuned for performance, allowing AI developers to optimize query execution and reduce latency, which is critical for real-time AI applications.\n",
        "\n",
        "In summary, NoSQL databases offer a versatile and scalable solution for handling various data-related tasks in AI projects. Their flexibility, scalability, and support for diverse data types make them well-suited for the complexities of AI applications. However, the choice of the specific NoSQL database and data model should align with the requirements of the AI project at hand."
      ],
      "metadata": {
        "id": "z5p3M8lbsWXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MARQ0WeYxTvX",
        "outputId": "d20eddc1-777f-43e2-f0ae-dd31846531b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.4.2 pymongo-4.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MongoDB is a popular NoSQL database. You can use the pymongo library to interact with MongoDB.\n",
        "import pymongo\n",
        "\n",
        "# Connect to MongoDB\n",
        "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"mydatabase\"]\n",
        "\n",
        "# Create a collection (similar to a table in SQL)\n",
        "collection = db[\"mycollection\"]\n",
        "\n",
        "# Insert a document (similar to a row in SQL)\n",
        "data = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}\n",
        "collection.insert_one(data)\n",
        "\n",
        "# Find documents\n",
        "result = collection.find({\"name\": \"John\"})\n",
        "for doc in result:\n",
        "    print(doc)\n"
      ],
      "metadata": {
        "id": "acA7eP6nnMJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cassandra Database (Cassandra Driver)\n",
        "\n",
        "NoSQL databases can be valuable when dealing with **unstructured data**\n",
        "\n",
        "**NoSQL Databases** (e.g., MongoDB, Cassandra):\n",
        "\n",
        "Relevance: NoSQL databases are commonly used in AI and machine learning projects, especially when dealing with large and unstructured data. They are well-suited for handling data types like text, images, and sensor data.\n",
        "\n",
        "Importance: Proficiency in NoSQL databases can be valuable for data preprocessing, storage, and retrieval in AI applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "i6uGfX9coLeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cassandra-driver"
      ],
      "metadata": {
        "id": "wAw6Sd9UyUle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cassandra is a distributed NoSQL database. You can use the cassandra-driver library to interact with Cassandra.\n",
        "\n",
        "from cassandra.cluster import Cluster\n",
        "\n",
        "# Connect to Cassandra\n",
        "cluster = Cluster(['localhost'])\n",
        "session = cluster.connect('mykeyspace')\n",
        "\n",
        "# Insert data\n",
        "session.execute(\"INSERT INTO mytable (id, name) VALUES (1, 'John')\")\n",
        "\n",
        "# Query data\n",
        "rows = session.execute(\"SELECT * FROM mytable WHERE id = 1\")\n",
        "for row in rows:\n",
        "    print(row.name)\n"
      ],
      "metadata": {
        "id": "AW8X0tKFnTTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Microsoft SQL Server (pyodbc):\n",
        "\n",
        "Proficiency in SQL (or SQL Server) is generally considered important for **data-related tasks** in AI.\n",
        "\n",
        "Relevance: SQL databases, including Microsoft SQL Server, are widely used for structured data storage and retrieval. Many organizations use SQL databases for various data-related tasks.\n",
        "\n",
        "Importance: Proficiency in SQL is important for managing structured data, performing data analysis, and integrating AI solutions with existing databases."
      ],
      "metadata": {
        "id": "t7c6ONJsn9v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In AI projects involving SQL Server, there are several important data-related tasks and considerations:\n",
        "\n",
        "- Data Collection: Gathering relevant data from various sources, such as databases, external APIs, and data lakes, is a crucial first step. SQL Server can be used to store and manage this collected data.\n",
        "\n",
        "- Data Preprocessing: Cleaning, transforming, and preparing data for AI model training is essential. SQL Server provides tools for data preprocessing, such as data cleaning, normalization, and feature engineering.\n",
        "\n",
        "- Data Storage: SQL Server serves as a reliable and scalable database system to store structured data. It can handle large datasets efficiently.\n",
        "\n",
        "- Data Integration: Integrating data from multiple sources and merging datasets is often required for AI projects. SQL Server's ETL (Extract, Transform, Load) capabilities can be used for this purpose.\n",
        "\n",
        "- Data Exploration: Exploring and visualizing data to gain insights is essential. SQL Server Reporting Services (SSRS) and Power BI can be integrated with SQL Server to create data dashboards and reports.\n",
        "\n",
        "- Model Training Data: Preparing datasets for model training, including creating training, validation, and test sets, is a key task. SQL Server can be used to partition and manage these datasets.\n",
        "\n",
        "- Model Deployment: Deploying AI models as SQL Server stored procedures or using SQL Server Machine Learning Services allows you to run predictions and analysis within the database.\n",
        "\n",
        "- Monitoring and Maintenance: Regularly monitoring data quality, model performance, and database health is crucial. SQL Server provides monitoring and maintenance tools.\n",
        "\n",
        "- Security and Privacy: Ensuring data security and compliance with privacy regulations (e.g., GDPR) is essential. SQL Server offers robust security features, including encryption and access control.\n",
        "\n",
        "- Scalability: As AI projects grow, the database infrastructure must be scalable. SQL Server can be configured for horizontal scaling using technologies like SQL Server AlwaysOn Availability Groups.\n",
        "\n",
        "- Data Backup and Recovery: Implementing data backup and recovery strategies is vital to safeguard against data loss or system failures.\n",
        "\n",
        "- Real-Time Data: Some AI applications require real-time data processing. SQL Server supports stream processing and can handle real-time data ingestion and analysis.\n",
        "\n",
        "- Version Control: Managing versions of databases and AI models is essential for reproducibility. Tools like SQL Server Data Tools (SSDT) can assist with version control.\n",
        "\n",
        "- Collaboration: Collaborating with data engineers, data scientists, and other team members is crucial for the success of AI projects. SQL Server can facilitate data sharing and collaboration.\n",
        "\n",
        "- Cloud Integration: Integrating SQL Server with cloud services like Azure can provide additional scalability, storage options, and AI capabilities.\n",
        "\n",
        "In summary, SQL Server plays a significant role in various data-related tasks within AI projects, from data collection and storage to preprocessing, model training, and deployment. It offers a robust and versatile platform for managing and processing data in AI applications."
      ],
      "metadata": {
        "id": "jFhEDGc3rcGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyodbc"
      ],
      "metadata": {
        "id": "Zc0_agFzyi0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use the pyodbc library to interact with Microsoft SQL Server:\n",
        "\n",
        "\n",
        "import pyodbc\n",
        "\n",
        "# Connect to SQL Server\n",
        "conn = pyodbc.connect('Driver={SQL Server};'\n",
        "                      'Server=localhost;'\n",
        "                      'Database=mydb;'\n",
        "                      'Trusted_Connection=yes;')\n",
        "\n",
        "# Create a cursor\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Insert data\n",
        "cursor.execute(\"INSERT INTO mytable (id, name) VALUES (1, 'John')\")\n",
        "conn.commit()\n",
        "\n",
        "# Query data\n",
        "cursor.execute(\"SELECT * FROM mytable WHERE id = 1\")\n",
        "for row in cursor:\n",
        "    print(row.name)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "BS0VpQwTnTWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # GraphQL (Graphene-Python):\n",
        "\n",
        " GraphQL can be useful for building efficient **data retrieval APIs**.\n",
        "\n",
        " Relevance: GraphQL is a query language for APIs, and it can be used to efficiently fetch data from databases or other data sources. While not directly related to AI, it can be beneficial when building APIs to serve AI models.\n",
        "\n",
        " Importance: It may be valuable for AI professionals who work on developing APIs and data retrieval systems."
      ],
      "metadata": {
        "id": "p4U0tT5jsyDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install graphene"
      ],
      "metadata": {
        "id": "U1LTQfmEytaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GraphQL is a query language for APIs. You can use libraries like graphene to create GraphQL APIs in Python.\n",
        "\n",
        "from graphene import ObjectType, String, Int, Schema\n",
        "\n",
        "class Query(ObjectType):\n",
        "    hello = String(name=String(default_value=\"World\"))\n",
        "    square = Int(x=Int())\n",
        "\n",
        "    def resolve_hello(self, info, name):\n",
        "        return f\"Hello, {name}!\"\n",
        "\n",
        "    def resolve_square(self, info, x):\n",
        "        return x * x\n",
        "\n",
        "schema = Schema(query=Query)\n",
        "result = schema.execute(\"{ hello, square(x: 5) }\")\n",
        "print(result.data)\n"
      ],
      "metadata": {
        "id": "uYqq-ud2nTYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}